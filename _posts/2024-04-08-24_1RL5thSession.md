---
title: "[06주차/강화학습 세션] DQN / DDQN"
excerpt: "DQN, 슬롯머신 구현" # 미리보기로 보이는 부분
categories: 24-1강화학습세션
tags: 
    - [강화학습, 정규세션]
toc: true
toc_sticky: true
comments: true
author: Jimin Lee

date: 2024-04-08

---

# 6주차 강화학습 세션

## 요약
- 이정연 벗께서 이미지 데이터 처리에 용이한 CNN 모델 발표를 해주셨습니다. 
- DQN, Double-Q learning, DDQN에 대해 학습했습니다. 
- 슬롯머신 문제를 환경부터 agent 코드까지 구현했습니다. 

- 구체적인 개인 발표 내용은 추후 **[개념정리] 카테고리**에서 확인하실 수 있습니다.  

## 개인 발표

- 📗 **CNN** : 이정연 벗

이미지 처리에 특화된 CNN 모델에 대해 설명해주셨습니다. CNN의 각 구성요소와 학습의 특징을 잘 짚어주셨습니다! 

## 강화학습 세션

- 📗 **DQN, Double-Q learning, DDQN, 강화학습 총정리**
- 👩‍💻 **슬롯머신 구현**

Q러닝의 가치 함수를 신경망으로 근사한 DQN에 대해 학습했습니다. DQN의 오프폴리쉬를 구현하는 방법, 리플레이 메모리의 특성과 DQN의 학습에 대해 설명했습니다. Q 러닝이 max Q값을 업데이트의 목표치로 설정하기 때문에 발생하는 overestimated 문제를 해결한 Double Q-learning을 소개하고, Double Q-learning과 DQN이 합쳐진 DDQN을 소개했습니다. 

본격적인 구현에 들어가기 앞서, 간단한 강화학습 예제를 0부터 해결해나가는 과제를 수행했습니다. 3개의 레버가 달린 슬롯머신 환경을 구현하고, DQN Agent를 물리는 코드를 구현했습니다. 

## 사진




